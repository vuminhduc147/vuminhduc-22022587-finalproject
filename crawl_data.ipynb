{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import traceback\n",
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "def atexit_handler():\n",
    "    input(\"\\n\\nPress Enter to exit...\")\n",
    "\n",
    "\n",
    "atexit.register(atexit_handler)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Post:\n",
    "    url: str\n",
    "    created_at: int = None\n",
    "    content: str = None\n",
    "    comment_count: int = None\n",
    "    comments: str = None\n",
    "    reactions: str = None\n",
    "    share_count: str = None\n",
    "\n",
    "\n",
    "class Driver(webdriver.Chrome):\n",
    "    def close_popup(self):\n",
    "        time.sleep(2)\n",
    "        btn_close = self.find_element(\n",
    "            By.CSS_SELECTOR, \"[role='dialog'] [aria-label='Close']\")\n",
    "        btn_close.click()\n",
    "\n",
    "    def scroll_to_bottom(self):\n",
    "        self.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "\n",
    "class Helper:\n",
    "    @staticmethod\n",
    "    def try_func(func, *args, max_try=1, delay=1, **kwargs):\n",
    "        try_count = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception:\n",
    "                if try_count >= max_try:\n",
    "                    raise\n",
    "\n",
    "            try_count += 1\n",
    "            time.sleep(delay)\n",
    "\n",
    "    @staticmethod\n",
    "    def cache(key=None):\n",
    "        cache_dir = os.path.join(os.getcwd(), \".cache\")\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                nonlocal key\n",
    "\n",
    "                if callable(key):\n",
    "                    _key = key(*args, **kwargs)\n",
    "                else:\n",
    "                    _key = func.__name__\n",
    "\n",
    "                fp = os.path.join(cache_dir, _key)\n",
    "                if os.path.exists(fp):\n",
    "                    try:\n",
    "                        with open(fp, \"rb\") as f:\n",
    "                            cached = pickle.load(f)\n",
    "                            return cached\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                result = func(*args, **kwargs)\n",
    "\n",
    "                with open(fp, \"wb\") as f:\n",
    "                    pickle.dump(result, f)\n",
    "\n",
    "                return result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        return decorator\n",
    "\n",
    "\n",
    "class CrawlPostHelper:\n",
    "    @staticmethod\n",
    "    def _get_root_elm(driver: Driver):\n",
    "        return driver.find_element(By.CSS_SELECTOR, \"[role='article'][aria-posinset]\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_creation_time(driver: Driver):\n",
    "        match = re.search(r'{\"creation_time\":(\\d+),', driver.page_source)\n",
    "        creation_time = match.group(1)\n",
    "        return creation_time\n",
    "\n",
    "    @staticmethod\n",
    "    def get_content(driver: Driver):\n",
    "        root_elm = CrawlPostHelper._get_root_elm(driver)\n",
    "        content = root_elm.find_element(\n",
    "            By.CSS_SELECTOR, \"[dir='auto']:has(div[id])\").text\n",
    "        return content\n",
    "\n",
    "    @staticmethod\n",
    "    def get_reactions(driver: Driver):\n",
    "        reactions = []\n",
    "        match = re.search(\n",
    "            r'\"reaction_count\":{.*?}(?=,\"reaction_display_config\")', driver.page_source)\n",
    "        s = match.group(0)\n",
    "        data = json.loads(\"\".join([\"{\", s, \"}\"]))\n",
    "\n",
    "        edges = data[\"top_reactions\"][\"edges\"]\n",
    "        for edge in edges:\n",
    "            reaction_data = {\n",
    "                \"name\": edge[\"node\"][\"localized_name\"],\n",
    "                \"count\": edge[\"reaction_count\"],\n",
    "            }\n",
    "            reactions.append(reaction_data)\n",
    "        return reactions\n",
    "\n",
    "    @staticmethod\n",
    "    def get_share_count(driver: Driver):\n",
    "        match = re.search(\n",
    "            r'\"share_count\":\\{\"count\":(\\d+),', driver.page_source)\n",
    "        share_count = match.group(1)\n",
    "        return share_count\n",
    "\n",
    "    @staticmethod\n",
    "    def get_comment_count(driver: Driver):\n",
    "        match = re.search(r'\"total_comment_count\":(\\d+),', driver.page_source)\n",
    "        comment_count = match.group(1)\n",
    "        return comment_count\n",
    "\n",
    "    @staticmethod\n",
    "    def get_comments(driver: Driver):\n",
    "        comments = []\n",
    "        root_elm = CrawlPostHelper._get_root_elm(driver)\n",
    "        li_elms = root_elm.find_elements(By.CSS_SELECTOR, \"h3 ~ ul > li\")\n",
    "        for elm in li_elms:\n",
    "            user_elm = elm.find_element(\n",
    "                By.CSS_SELECTOR, \".x1y1aw1k.xn6708d.xwib8y2.x1ye3gou > span\")\n",
    "\n",
    "            try:\n",
    "                content = elm.find_element(\n",
    "                    By.CSS_SELECTOR, \"[style='text-align: start;']\").text\n",
    "            except NoSuchElementException:\n",
    "                content = \"\"\n",
    "\n",
    "            comment = {\n",
    "                \"user\": user_elm.text,\n",
    "                \"content\": content,\n",
    "            }\n",
    "            comments.append(comment)\n",
    "        return comments\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    driver: Driver\n",
    "\n",
    "    def __init__(self, post_limit: int = 100) -> None:\n",
    "        self.post_limit = post_limit\n",
    "\n",
    "    def run(self):\n",
    "        with Driver() as self.driver:\n",
    "            try:\n",
    "                self.driver.get(\"https://www.facebook.com/xalo.zodiac\")\n",
    "                self.driver.close_popup()\n",
    "\n",
    "                posts = self.get_posts()\n",
    "                result = []\n",
    "\n",
    "                success_count = fail_count = 0\n",
    "                for i, post in enumerate(posts, start=1):\n",
    "                    try:\n",
    "                        self.crawl_post(post)\n",
    "                        result.append(post)\n",
    "                        success_count += 1\n",
    "                    except Exception:\n",
    "                        fail_count += 1\n",
    "                    print(\n",
    "                        f\"\\r- Post {i}/{len(posts)} - success {success_count} - fail {fail_count}\", end=\"\")\n",
    "\n",
    "                print()\n",
    "                return result\n",
    "            except Exception:\n",
    "                print(traceback.format_exc())\n",
    "                input(\"Press Enter to close chrome...\")\n",
    "                raise\n",
    "\n",
    "    @Helper.cache()\n",
    "    def get_posts(self):\n",
    "        posts = []\n",
    "        while True:\n",
    "            articles_elm = self.driver.find_elements(\n",
    "                By.CSS_SELECTOR, \"[role='article'][aria-posinset]\")\n",
    "\n",
    "            if len(articles_elm) >= self.post_limit:\n",
    "                break\n",
    "\n",
    "            self.driver.scroll_to_bottom()\n",
    "            time.sleep(2)\n",
    "\n",
    "        articles_elm = articles_elm[: self.post_limit]\n",
    "\n",
    "        for elm in articles_elm:\n",
    "            delta_date_elm = elm.find_element(\n",
    "                By.CSS_SELECTOR, \"a[aria-label][href]:has(span)\")\n",
    "\n",
    "            href = delta_date_elm.get_attribute(\"href\")\n",
    "            article = Post(url=href)\n",
    "            posts.append(article)\n",
    "\n",
    "        return posts\n",
    "\n",
    "    @Helper.cache(key=lambda self, post: hashlib.md5(post.url.encode(\"ascii\")).hexdigest())\n",
    "    def crawl_post(self, post: Post):\n",
    "        self.driver.get(post.url)\n",
    "        post.created_at = CrawlPostHelper.get_creation_time(self.driver)\n",
    "        post.content = CrawlPostHelper.get_content(self.driver)\n",
    "        post.reactions = CrawlPostHelper.get_reactions(self.driver)\n",
    "        post.share_count = CrawlPostHelper.get_share_count(self.driver)\n",
    "        post.comment_count = CrawlPostHelper.get_comment_count(self.driver)\n",
    "        post.comments = CrawlPostHelper.get_comments(self.driver)\n",
    "\n",
    "\n",
    "worker = Worker(post_limit=100)\n",
    "posts = worker.run()\n",
    "\n",
    "data = []\n",
    "for post in posts:\n",
    "    data.append(asdict(post))\n",
    "\n",
    "with open(\"data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
